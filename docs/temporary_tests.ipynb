{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7791ac88",
   "metadata": {},
   "source": [
    "# Temporary tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d9e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5729689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_text(num_phrases):\n",
    "    phrases = []\n",
    "    for i in range(1, num_phrases + 1):\n",
    "        phrase = f\"Phrase {i}.\"\n",
    "        phrases.append(phrase)\n",
    "\n",
    "    fake_text = \" \".join(phrases)\n",
    "    return fake_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e22bf312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phrase 1', 'Phrase 2', 'Phrase 3', 'Phrase 4', 'Phrase 5']\n"
     ]
    }
   ],
   "source": [
    "DEMO_TEXT = generate_fake_text(20)\n",
    "print(DEMO_TEXT.split(\". \")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a693de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 9. Phrase 10. Phrase 11. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\n",
      "Phrase 1. Phrase 2. Phrase 3. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 10. Phrase 11. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fragment(text: str, deletion_prob: float) -> str:\n",
    "    \"\"\"Fragment a text by removing sentences randomly.\n",
    "\n",
    "    Args:\n",
    "        deletion_prob (float): The probability of sentence deletion.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with sentences deleted.\n",
    "    \"\"\"\n",
    "    sentences = text.split(\".\")\n",
    "    num_sentences_to_delete = int(deletion_prob * len(sentences))\n",
    "    if num_sentences_to_delete > 0:\n",
    "        deletion_indices = random.sample(range(len(sentences)),\n",
    "                                            num_sentences_to_delete)\n",
    "        for index in sorted(deletion_indices, reverse=True):\n",
    "            del sentences[index]\n",
    "    return \".\".join(sentences)\n",
    "\n",
    "print(fragment(DEMO_TEXT, 0))\n",
    "print(fragment(DEMO_TEXT, 0.25))\n",
    "print(fragment(DEMO_TEXT, 1))\n",
    "# print(fragment(DEMO_TEXT, 2)) # Error Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e7b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 8. Phrase 11. Phrase 12. Phrase 13. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19.\n"
     ]
    }
   ],
   "source": [
    "def fragment(text: str, deletion_prob: float) -> str:\n",
    "    \"\"\"Fragment a text by removing sentences randomly.\n",
    "\n",
    "    Args:\n",
    "        deletion_prob (float): The probability of sentence deletion.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with sentences deleted.\n",
    "    \"\"\"\n",
    "    sentences = text.split(\".\")\n",
    "    num_sentences_to_delete = int(deletion_prob * len(sentences))\n",
    "    if num_sentences_to_delete > 0:\n",
    "        deletion_indices = random.sample(range(len(sentences)),\n",
    "                                            num_sentences_to_delete)\n",
    "        for index in sorted(deletion_indices, reverse=True):\n",
    "            del sentences[index]\n",
    "    return \".\".join(sentences)\n",
    "\n",
    "print(fragment(DEMO_TEXT, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "303ffee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from stemmabench.stemma_generator import Stemma\n",
    "from stemmabench.config_parser import StemmaBenchConfig\n",
    "from loguru import logger\n",
    "# Set logging level to info\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d96529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = StemmaBenchConfig(**{\n",
    "    \"meta\": {\n",
    "      \"language\": \"eng\"  \n",
    "    },\n",
    "    \"stemma\": {\n",
    "        \"depth\": 2,\n",
    "        \"width\": {\n",
    "            \"law\": \"Uniform\",\n",
    "            \"min\": 2,\n",
    "            \"max\": 3\n",
    "        }\n",
    "    },\n",
    "    \"variants\": {\n",
    "        \"sentences\": {\n",
    "            \"duplicate\": {\n",
    "                \"args\": {\"nbr_words\": 1},\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.05\n",
    "            },\n",
    "            \"delete\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.01\n",
    "            }\n",
    "        },\n",
    "        \"words\": {\n",
    "            \"synonym\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.05,\n",
    "                \"args\": {}\n",
    "            },\n",
    "            \"mispell\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.001,\n",
    "                \"args\": {}\n",
    "            },\n",
    "            \"omit\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.001,\n",
    "                \"args\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfc61901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'clean',\n",
       " 'delete',\n",
       " 'duplicate',\n",
       " 'nbr_words',\n",
       " 'sentence',\n",
       " 'words']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is the method has been added during the update (need to run `invoke install` again)\n",
    "from stemmabench.textual_units import sentence\n",
    "phrase = sentence.Sentence(\"Phrase\")\n",
    "dir(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b1a5a",
   "metadata": {},
   "source": [
    "Create a stemma object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b082d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree({\n",
       "  \"Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 9. Phrase 10. Phrase 11. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\": {\n",
       "    \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": {\n",
       "      \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase s8 phrase 19 phrase 20.\"\n",
       "      ],\n",
       "      \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 articulate 7 word 8 phrase 9 phrase 10 articulate 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 articulate 5 phrase 6 articulate 7 give voice 8 phrase 9 phrase 10 articulate 11 articulate 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 articulate 7 word 8 phrase 9 phrase 10 articulate 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 word 19 phrase 20.\"\n",
       "      ]\n",
       "    },\n",
       "    \"Phrase 1 give voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15. Phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": {\n",
       "      \"Phrase 1 give voice 2 phrase 3 phrase 4 formulate 5 phrase 6 phrase 7 phrase 8 give voice 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 give voice 2 phrase 3 phrase 4 formulate 5 phrase 6 give voice 7 phrase 8 give in voice 9 phrase 10 articulate 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 give voice 2 phrase 3 phrase 4 formulate 5 phrase 6 phrase 7 phrase 8 give voice 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\"\n",
       "      ],\n",
       "      \"Phrase 1 give voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 yield voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 formulate 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 give voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\"\n",
       "      ]\n",
       "    }\n",
       "  }\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a stemma object.\n",
    "stemma = Stemma(original_text=DEMO_TEXT, config=config)\n",
    "\n",
    "# Generate a tradition.\n",
    "stemma.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82129c",
   "metadata": {},
   "source": [
    "Each text can be accessed through its lookup table, which can be used to get the tree stemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c80925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemma.texts_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07960b4",
   "metadata": {},
   "source": [
    "It is also possible to access the edges describing only the manuscript names and their family relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58334fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', '0:0'),\n",
       " ('0', '0:1'),\n",
       " ('0:0', '0:0:0'),\n",
       " ('0:0', '0:0:1'),\n",
       " ('0:1', '0:1:0'),\n",
       " ('0:1', '0:1:1'),\n",
       " ('0:0:0', '0:0:0:0'),\n",
       " ('0:0:0', '0:0:0:1'),\n",
       " ('0:0:1', '0:0:1:0'),\n",
       " ('0:0:1', '0:0:1:1'),\n",
       " ('0:0:0', '0:0:0:0'),\n",
       " ('0:0:0', '0:0:0:1'),\n",
       " ('0:0:1', '0:0:1:0'),\n",
       " ('0:0:1', '0:0:1:1')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemma.edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
