{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7791ac88",
   "metadata": {},
   "source": [
    "# Temporary tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d9e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5729689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_text(num_phrases):\n",
    "    phrases = []\n",
    "    for i in range(1, num_phrases + 1):\n",
    "        phrase = f\"Phrase {i}.\"\n",
    "        phrases.append(phrase)\n",
    "\n",
    "    fake_text = \" \".join(phrases)\n",
    "    return fake_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22bf312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5.  \n",
      "['Phrase 1', 'Phrase 2', 'Phrase 3', 'Phrase 4', 'Phrase 5']\n"
     ]
    }
   ],
   "source": [
    "DEMO_TEXT = generate_fake_text(20)\n",
    "print(f\"\"\"{DEMO_TEXT[:50]} \\n{DEMO_TEXT.split(\". \")[:5]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a693de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 9. Phrase 10. Phrase 11. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\n",
      "Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 7. Phrase 9. Phrase 10. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CASE 1: REMOVE INDEPENDENTLY A RANDOM NUMBER OF SEQUENCES (see branch: stb_fragment_ays1).\n",
    "def fragment(text: str, frag_rate: float) -> str:\n",
    "    \"\"\"Fragment a text by removing sentences randomly.\n",
    "    # Sentences are removed independently from each other.\n",
    "    # Equivalent to add a `delete` method to the Sentence class with a \n",
    "    # ProbabilisticConfig object as parameter (law: `Bernouilli`, rate: float).\n",
    "\n",
    "    Args:\n",
    "        frag_rate (float): The probability of sentence deletion.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with sentences deleted.\n",
    "    \"\"\"\n",
    "    if not 0 <= frag_rate <= 1:\n",
    "        raise ValueError(\"Probability larger than one or is negative.\")\n",
    "    \n",
    "    sentences = text.split(\".\")\n",
    "    nbr_to_delete = int(frag_rate * len(sentences))\n",
    "    if nbr_to_delete > 0:\n",
    "        deletion_indices = random.sample(range(len(sentences)),\n",
    "                                            nbr_to_delete)\n",
    "        for index in sorted(deletion_indices, reverse=True):\n",
    "            del sentences[index]\n",
    "    return \".\".join(sentences)\n",
    "\n",
    "print(fragment(DEMO_TEXT, 0))\n",
    "print(fragment(DEMO_TEXT, 0.25))\n",
    "print(fragment(DEMO_TEXT, 1))\n",
    "# print(fragment(DEMO_TEXT, 2)) # Error Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98e7b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 Error\n",
      "0.0 - 20 sentences - Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 9. Phrase 10. Phrase 11. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\n",
      "0.25 - 15 sentences - Phrase 1. Phrase 2. Phrase 3. Phrase 9. Phrase 10. Phrase 11. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\n",
      "0.5 - 10 sentences - Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 19. Phrase 20.\n",
      "0.75 - 4 sentences - Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5\n",
      "1.0 - 0 sentences - \n",
      "2.0 Error\n"
     ]
    }
   ],
   "source": [
    "# CASE2: REMOVING ONE SEQUENCE OF SENTENCES.   \n",
    "def fragment_sequence(text: str, frag_rate: float, punc: str = \".\") -> str:\n",
    "    \"\"\"\n",
    "    Fragment a text by randomly removing ONE sequence of sentences whose\n",
    "    length is expressed as a percentage of the text length.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be fragmented.\n",
    "        frag_rate (float): The rate of sentence deletion (0 <= frag_rate <= 1).\n",
    "            Represents the percentage of sentences to be deleted.\n",
    "        punc (str, optional): The punctuation used to split the text into sentences.\n",
    "            Default is period/full stop (\".\").\n",
    "    \n",
    "    Returns:\n",
    "        str: The fragmented text with sentences deleted.\n",
    "    \"\"\"\n",
    "    if not 0 <= frag_rate <= 1:\n",
    "        raise ValueError(\"Probability or rate larger than one or is negative.\")\n",
    "    # Split the text into sentences using the specified punctuation.\n",
    "    sentences = text.split(punc)\n",
    "    # Calculate the total number of sentences and the number of sentences to delete.\n",
    "    num_sentences = len(sentences)\n",
    "    num_sentences_to_delete = round(num_sentences * frag_rate)\n",
    "    # Choose a random starting point for the sequence of sentences to be deleted.\n",
    "    start_frag_location = min(random.choice(range(num_sentences)),\n",
    "                              num_sentences - num_sentences_to_delete)\n",
    "    # Determine the ending point of the fragment to be deleted.\n",
    "    end_frag_location = start_frag_location + num_sentences_to_delete\n",
    "    # Delete the selected sequence of sentences from the list.\n",
    "    del sentences[start_frag_location:end_frag_location]\n",
    "\n",
    "    # Join the remaining sentences back into a single text.\n",
    "    fragmented_text = punc.join(sentences)\n",
    "\n",
    "    return fragmented_text\n",
    "\n",
    "for rate in [-1, 0.0, 0.25, 0.5, 0.75, 1.0, 2.0]:\n",
    "    try:\n",
    "        res = fragment_sequence(DEMO_TEXT, rate)\n",
    "        length = len(res.split(\".\")) - 1 # approx\n",
    "        print(f\"{rate} - {length} sentences - {res}\")\n",
    "    except:\n",
    "        print(rate, \"Error\")\n",
    "        pass\n",
    "# print(fragment(DEMO_TEXT, 2)) # Error Expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef631104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[6, 9]\n"
     ]
    }
   ],
   "source": [
    "# CASE 3: REMOVING `MANY` (A RANDOM NUMBER OF) SEQUENCES OF SENTENCES.\n",
    "## Case 3.1: simple case \n",
    "### * constant length of fragment locations\n",
    "### * uniform repartition of fragment locations whithin the document\n",
    "def fragment_sequences(text: str, frag_rate: float, punc: str = \".\") -> str:\n",
    "    \"\"\"\n",
    "    Fragment a text by randomly removing MANY sequences of sentences. The total\n",
    "    number of sentences to be deleted in the text is the sum of the sequences length and \n",
    "    is expressed as a percentage of the text length.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be fragmented.\n",
    "        frag_rate (float): The rate of sentence deletion (0 <= frag_rate <= 1).\n",
    "            Represents the percentage of sentences to be deleted.\n",
    "        punc (str, optional): The punctuation used to split the text into sentences.\n",
    "            Default is period/full stop (\".\").\n",
    "    \n",
    "    Returns:\n",
    "        str: The fragmented text with sentences deleted.\n",
    "    \"\"\"\n",
    "    if not 0 <= frag_rate <= 1:\n",
    "        raise ValueError(\"Probability or rate larger than one or is negative.\")\n",
    "    # Split the text into sentences using the specified punctuation.\n",
    "    sentences = text.split(punc)\n",
    "    # Calculate the total number of sentences and the number of sentences to delete.\n",
    "    num_sentences = len(sentences)\n",
    "    num_sentences_to_delete = round(num_sentences * frag_rate)\n",
    "    # Choose a random starting point for the sequence of sentences to be deleted.\n",
    "    start_frag_location = min(random.choice(range(num_sentences)),\n",
    "                              num_sentences - num_sentences_to_delete)\n",
    "    # Determine the ending point of the fragment to be deleted.\n",
    "    end_frag_location = start_frag_location + num_sentences_to_delete\n",
    "    # Delete the selected sequence of sentences from the list.\n",
    "    del sentences[start_frag_location:end_frag_location]\n",
    "\n",
    "    # Join the remaining sentences back into a single text.\n",
    "    fragmented_text = punc.join(sentences)\n",
    "\n",
    "    return fragmented_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "303ffee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from stemmabench.stemma_generator import Stemma\n",
    "from stemmabench.config_parser import StemmaBenchConfig\n",
    "from loguru import logger\n",
    "# Set logging level to info\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0725b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(round(0.4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d96529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = StemmaBenchConfig(**{\n",
    "    \"meta\": {\n",
    "      \"language\": \"eng\"  \n",
    "    },\n",
    "    \"stemma\": {\n",
    "        \"depth\": 2,\n",
    "        \"width\": {\n",
    "            \"law\": \"Uniform\",\n",
    "            \"min\": 2,\n",
    "            \"max\": 3\n",
    "        }\n",
    "    },\n",
    "    \"variants\": {\n",
    "        \"sentences\": {\n",
    "            \"duplicate\": {\n",
    "                \"args\": {\"nbr_words\": 1},\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.05\n",
    "            },\n",
    "            \"delete\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.01\n",
    "            }\n",
    "        },\n",
    "        \"words\": {\n",
    "            \"synonym\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.05,\n",
    "                \"args\": {}\n",
    "            },\n",
    "            \"mispell\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.001,\n",
    "                \"args\": {}\n",
    "            },\n",
    "            \"omit\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.001,\n",
    "                \"args\": {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfc61901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check is the method has been added during the update (need to run `invoke install` again)\n",
    "# from stemmabench.textual_units import sentence\n",
    "# phrase = sentence.Sentence(\"Phrase\")\n",
    "# dir(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b1a5a",
   "metadata": {},
   "source": [
    "Create a stemma object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b082d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree({\n",
       "  \"Phrase 1. Phrase 2. Phrase 3. Phrase 4. Phrase 5. Phrase 6. Phrase 7. Phrase 8. Phrase 9. Phrase 10. Phrase 11. Phrase 12. Phrase 13. Phrase 14. Phrase 15. Phrase 16. Phrase 17. Phrase 18. Phrase 19. Phrase 20.\": {\n",
       "    \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": {\n",
       "      \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 phrase 7 phrase 8 phrase 9 phrase 10 phrase 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase s8 phrase 19 phrase 20.\"\n",
       "      ],\n",
       "      \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 articulate 7 word 8 phrase 9 phrase 10 articulate 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 articulate 5 phrase 6 articulate 7 give voice 8 phrase 9 phrase 10 articulate 11 articulate 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 phrase 2 phrase 3 articulate 4 phrase 5 phrase 6 articulate 7 word 8 phrase 9 phrase 10 articulate 11 phrase 12 phrase 13 phrase 14 phrase 15 phrase 16 phrase 17 phrase 18 word 19 phrase 20.\"\n",
       "      ]\n",
       "    },\n",
       "    \"Phrase 1 give voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15. Phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": {\n",
       "      \"Phrase 1 give voice 2 phrase 3 phrase 4 formulate 5 phrase 6 phrase 7 phrase 8 give voice 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 give voice 2 phrase 3 phrase 4 formulate 5 phrase 6 give voice 7 phrase 8 give in voice 9 phrase 10 articulate 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 give voice 2 phrase 3 phrase 4 formulate 5 phrase 6 phrase 7 phrase 8 give voice 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\"\n",
       "      ],\n",
       "      \"Phrase 1 give voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\": [\n",
       "        \"Phrase 1 yield voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 formulate 18 phrase 19 phrase 20.\",\n",
       "        \"Phrase 1 give voice 2 phrase 3 phrase 4 phrase 5 phrase 6 phrase 7 phrase 8 word 9 phrase 10 phrase 11 phrase 12 phrase 13 word 14 phrase 15 phrase 16 phrase 17 phrase 18 phrase 19 phrase 20.\"\n",
       "      ]\n",
       "    }\n",
       "  }\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a stemma object.\n",
    "stemma = Stemma(original_text=DEMO_TEXT, config=config)\n",
    "\n",
    "# Generate a tradition.\n",
    "stemma.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82129c",
   "metadata": {},
   "source": [
    "Each text can be accessed through its lookup table, which can be used to get the tree stemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c80925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemma.texts_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07960b4",
   "metadata": {},
   "source": [
    "It is also possible to access the edges describing only the manuscript names and their family relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58334fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', '0:0'),\n",
       " ('0', '0:1'),\n",
       " ('0:0', '0:0:0'),\n",
       " ('0:0', '0:0:1'),\n",
       " ('0:1', '0:1:0'),\n",
       " ('0:1', '0:1:1'),\n",
       " ('0:0:0', '0:0:0:0'),\n",
       " ('0:0:0', '0:0:0:1'),\n",
       " ('0:0:1', '0:0:1:0'),\n",
       " ('0:0:1', '0:0:1:1'),\n",
       " ('0:0:0', '0:0:0:0'),\n",
       " ('0:0:0', '0:0:0:1'),\n",
       " ('0:0:1', '0:0:1:0'),\n",
       " ('0:0:1', '0:0:1:1')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemma.edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
